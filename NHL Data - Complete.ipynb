{
 "cells": [
  {
   "attachments": {
    "NHL-logo-banner.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![NHL-logo-banner.jpg](attachment:NHL-logo-banner.jpg)\n",
    "\n",
    "# Predicting NHL Wins\n",
    "\n",
    "By: Jillian Komskis, Joseph Perez, and Kenneth Thomas\n",
    "\n",
    "\n",
    "An outline of the project is as follows: \n",
    "1.  Objective\n",
    "2.  Load/filter the data                                                                  \n",
    "3.  Data correlation (heat map)\n",
    "4.  Seperate train/test sets\n",
    "5.  Feature scaling \n",
    "6.  Models: LR, 2nd-degree, 7th-degree\n",
    "7.  Regularization Models\n",
    "8.  Comparisons\n",
    "9.  Remove short-handed variables\n",
    "10.  New comparisons\n",
    "11. Extra Predictions\n",
    "12. Model Application\n",
    "13. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Our objective is to create a model that will predict the amount of wins an NHL team will have in an upcoming season based off certain inputs (feature variables). We have decided to use the following feature variables in our models: Goals-For, Goals-Against, Short-Handed Goals-For, Short-Handed Goals-Against, Penalties-in-Minutes, PowerPlay Percentage, and Penalty-Kill Percentage.\n",
    "\n",
    "We will focus our efforts on exploring team data during the seasons that Gary Bettman was commissioner of the National Hockey League (1993 – present) and in which 82 games were played, up until the data’s 2011 limitation. We will remove the 1993 season since teams in the NHL still played 84 games in Bettman’s first season as commissioner. We have also removed the shortened 1994 lockout season as there were only 48 games played that season. In effect, our data begins with the 1995 season. There is no data for the 2004 season since there were no games played due to a lockout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert inline statement to make sure plots are visible\n",
    "%matplotlib inline\n",
    "#this code was taken from the SLR class demo\n",
    "#in Jupyter, the '%' symbol is a \"magic command\". This prompt enaples matplotlib to work interactively.\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#this code was also taken from the SLR class demo\n",
    "#we are importing the numpy and pandas packages so that we may use the functions that come with these modules.\n",
    "#we imported matplotlib.pyplot because we will be doing a lot of plotting, and the shorthand 'plt' makes it easier \n",
    "#than having to type out matplotlib.pyplot every time we want to use it\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "#this code was taken from the Applying Learning Algorithms Class Demo\n",
    "#these are tools from the sklearn package that we can utilize later in the assignment\n",
    "#sklearn makes it easier to produce statistical models since the functions are pre-packaged\n",
    "from sklearn.model_selection import train_test_split\n",
    "#This code was also take from the Applying Learning Algorithms Class Demo\n",
    "#this code will allow us to set aside a test set from our data to test the accuracy of the training set\n",
    "import csv #imports the csv reading and writing module\n",
    "import seaborn as sns #Taken from the Bank Marketing Logistic example, allows us to create a heatmap\n",
    "sns.set(style='white')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "#This code was taken from http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the Data\n",
    "\n",
    "The following code pulls the data from the computer and then filters the relevant rows (from 1995 - 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code was written on our own\n",
    "with open('C:\\\\Users\\\\admin\\\\Desktop\\\\MS-BA\\\\Teams - NHL.csv', 'r') as nhl_file:\n",
    "    with open('C:\\\\Users\\\\admin\\\\Desktop\\\\MS-BA\\\\NHL Filtered.csv','w') as nhl_filtered:\n",
    "        for line in nhl_file:\n",
    "            line_list = []\n",
    "            line_list += line.split(',') #this is splitting each line into a list with each item signified by a \n",
    "                                         #separation by commas\n",
    "            try:\n",
    "                if int(line_list[0]) >= 1995: #we want the line for years after 1995\n",
    "                    if int(line_list[8] == '82'): #doesn't actually do anything, but is a good safety. Makes sure that \n",
    "                                                  #we only use seasons with 82 games\n",
    "                        print(line.strip(), file=nhl_filtered)\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "            except ValueError: #we are handling ValueErrors exceptions to deal with the title rows\n",
    "                print(line.strip(), file=nhl_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Insertion\n",
    "We are inserting columns for Goal Differential, Power Play Percentage, and Penalty Kill Percentage because we believe that these features may be valuable in predicting team wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_list = []\n",
    "with open('C:\\\\Users\\\\admin\\\\Desktop\\\\MS-BA\\\\NHL Filtered.csv','r+') as nhl_filtered:\n",
    "    for i in nhl_filtered:\n",
    "        all_list += [i.strip().split(',')]\n",
    "        \n",
    "    for k in all_list: #this code was written by hand to create the GoalDif category. It takes the goals for and \n",
    "                       #subtracts it from goals against\n",
    "        try:\n",
    "            GF = int(k[16])\n",
    "            GA = int(k[17])\n",
    "            goal_dif = GF - GA\n",
    "            k.insert(18,goal_dif) #inserts the column at the 18th index\n",
    "        except ValueError:\n",
    "            k.insert(18,'GoalDif') #for exceptions (the column heading line), it inserts a column heading for the \n",
    "                                   #category\n",
    "            pass\n",
    "            \n",
    "    for k in all_list: #this code was written by hand to create the powerplay percentage category. It takes powerplay \n",
    "                       #goals and divides it by the total number of powerplay chances\n",
    "        try:\n",
    "            PPG = int(k[22])\n",
    "            PPC = int(k[23])\n",
    "            PPP = PPG/PPC * 100 #gets it as a percentage\n",
    "            k.insert(24,PPP) #inserts a column at the 24th index\n",
    "        except ValueError:\n",
    "            k.insert(24,'PP%') #for exceptions (the column heading line), it inserts a column heading for the category\n",
    "            pass\n",
    "        \n",
    "    for k in all_list: #this code was written by hand to create the penalty kill percentage category. It takes Pentaly\n",
    "                       #Kill goals allowed and divides it by the total number of times the team was shorthanded\n",
    "        try:\n",
    "            PKG = int(k[26])\n",
    "            PKC = int(k[27])\n",
    "            PKP = PKG/PKC * 100 #gets it as a percentage\n",
    "            k.insert(28,PKP) #inserts a column at the 28th index\n",
    "        except ValueError:\n",
    "            k.insert(28,'PK%') #for exceptions (the column heading line), it inserts a column heading for the category\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from:\n",
    "#https://stackoverflow.com/questions/6916542/writing-list-of-strings-to-excel-csv-file-in-python\n",
    "with open('C:\\\\Users\\\\admin\\\\Desktop\\\\MS-BA\\\\NHL Filtered plus.csv','w') as nhl_filtered_plus:\n",
    "    wr = csv.writer(nhl_filtered_plus, dialect = 'excel')\n",
    "    wr.writerows(all_list)\n",
    "#converts a nested list into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data Set\n",
    "\n",
    "#### Analysis\n",
    "\n",
    "We will be using the Wins column as our target variable. From the data set, we have initially determined that the following categories are likely to be relevant to formulating a good model: Goals-For, Goals-Against, Goal Differential, Penalties-in-Minutes, Bench Minors, PowerPlay Goals, PowerPlay Chances, PowerPlay Percentage, Short-Handed Goals-Allowed, Penalty-Kill Goals-Allowed, Penalty-Kill Chances, Penalty-Kill Percentage, and Short-Handed Goals For."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\admin\\\\Desktop\\\\MS-BA\\\\NHL Filtered plus.csv')\n",
    "#taken from the second programming assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 30)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "#shows the shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>lgID</th>\n",
       "      <th>tmID</th>\n",
       "      <th>franchID</th>\n",
       "      <th>confID</th>\n",
       "      <th>divID</th>\n",
       "      <th>rank</th>\n",
       "      <th>playoff</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>...</th>\n",
       "      <th>PIM</th>\n",
       "      <th>BenchMinor</th>\n",
       "      <th>PPG</th>\n",
       "      <th>PPC</th>\n",
       "      <th>PP%</th>\n",
       "      <th>SHA</th>\n",
       "      <th>PKG</th>\n",
       "      <th>PKC</th>\n",
       "      <th>PK%</th>\n",
       "      <th>SHF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>NHL</td>\n",
       "      <td>ANA</td>\n",
       "      <td>ANA</td>\n",
       "      <td>WC</td>\n",
       "      <td>PC</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>1707</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>426</td>\n",
       "      <td>14.084507</td>\n",
       "      <td>5</td>\n",
       "      <td>81</td>\n",
       "      <td>423</td>\n",
       "      <td>19.148936</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>NHL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>BOS</td>\n",
       "      <td>EC</td>\n",
       "      <td>NE</td>\n",
       "      <td>2</td>\n",
       "      <td>CQF</td>\n",
       "      <td>82</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>1039</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>363</td>\n",
       "      <td>18.732782</td>\n",
       "      <td>7</td>\n",
       "      <td>67</td>\n",
       "      <td>341</td>\n",
       "      <td>19.648094</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>NHL</td>\n",
       "      <td>BUF</td>\n",
       "      <td>BUF</td>\n",
       "      <td>EC</td>\n",
       "      <td>NE</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>2195</td>\n",
       "      <td>14</td>\n",
       "      <td>76</td>\n",
       "      <td>477</td>\n",
       "      <td>15.932914</td>\n",
       "      <td>12</td>\n",
       "      <td>74</td>\n",
       "      <td>461</td>\n",
       "      <td>16.052061</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>NHL</td>\n",
       "      <td>CAL</td>\n",
       "      <td>CAL</td>\n",
       "      <td>WC</td>\n",
       "      <td>PC</td>\n",
       "      <td>2</td>\n",
       "      <td>CQF</td>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1524</td>\n",
       "      <td>24</td>\n",
       "      <td>71</td>\n",
       "      <td>386</td>\n",
       "      <td>18.393782</td>\n",
       "      <td>9</td>\n",
       "      <td>80</td>\n",
       "      <td>402</td>\n",
       "      <td>19.900498</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>NHL</td>\n",
       "      <td>CHI</td>\n",
       "      <td>CHI</td>\n",
       "      <td>WC</td>\n",
       "      <td>CE</td>\n",
       "      <td>2</td>\n",
       "      <td>CSF</td>\n",
       "      <td>82</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>1880</td>\n",
       "      <td>20</td>\n",
       "      <td>63</td>\n",
       "      <td>356</td>\n",
       "      <td>17.696629</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>447</td>\n",
       "      <td>14.541387</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year lgID tmID franchID confID divID  rank playoff   G   W ...   PIM  \\\n",
       "0  1995  NHL  ANA      ANA     WC    PC     4     NaN  82  35 ...  1707   \n",
       "1  1995  NHL  BOS      BOS     EC    NE     2     CQF  82  40 ...  1039   \n",
       "2  1995  NHL  BUF      BUF     EC    NE     5     NaN  82  33 ...  2195   \n",
       "3  1995  NHL  CAL      CAL     WC    PC     2     CQF  82  34 ...  1524   \n",
       "4  1995  NHL  CHI      CHI     WC    CE     2     CSF  82  40 ...  1880   \n",
       "\n",
       "   BenchMinor  PPG  PPC        PP%  SHA  PKG  PKC        PK% SHF  \n",
       "0          22   60  426  14.084507    5   81  423  19.148936  10  \n",
       "1          10   68  363  18.732782    7   67  341  19.648094  13  \n",
       "2          14   76  477  15.932914   12   74  461  16.052061  10  \n",
       "3          24   71  386  18.393782    9   80  402  19.900498  11  \n",
       "4          20   63  356  17.696629    7   65  447  14.541387  13  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head() #displays the first five rows of the data by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b8824072e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.heatmap(data.corr()) \n",
    "#Taken from the Bank Marketing Logistic Example\n",
    "#creates a heatmap that shows how correlated one variable is with another variable\n",
    "#Check the independence between the feature variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heatmap Analysis\n",
    "\n",
    "As shown in the heat map, ceartain variables such as Goals-For, Goals-Against, and Goal-Differential are highly correlated. This makes sense since Goal Differential is derived from these variables. The variables that we have chosen for our model do not show strong correlation with one another, which is a good sign that we chose appropriate variables during our preliminary analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating our target and feature variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[['W']]    # This pulls the target values from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    W\n",
       "0  35\n",
       "1  40\n",
       "2  33\n",
       "3  34\n",
       "4  40"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = data[['GF']]\n",
    "X2 = data[['GA']]\n",
    "X3 = data[['GoalDif']]\n",
    "X4 = data[['PIM']]\n",
    "X5 = data[['BenchMinor']]\n",
    "X6 = data[['PPG']]\n",
    "X7 = data[['PPC']]\n",
    "X8 = data[['PP%']]\n",
    "X9 = data[['SHA']]\n",
    "X10 = data[['PKG']]\n",
    "X11 = data[['PKC']]\n",
    "X12 = data[['PK%']]\n",
    "X13 = data[['SHF']]    \n",
    "# This pulls the feature values from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13] #concatenates all of the feature variables into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)\n",
    "#this code was borrowed and slightly adjusted from the Applying Learning Algorithms Class Demo\n",
    "#This code takes the variable X, the feature values, and splits it into two sets:\n",
    "#the training and test set, defined by the first two variables in the code\n",
    "#We are taking 20% of the data set and using the random_state 42\n",
    "#We will keep this random state constant throughout the assignment\n",
    "#If we do not, the randomly chosen numbers will be different every time the data is invoked, which will provide \n",
    "#inconsistent and useless results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463 Total data size.\n",
      "370 training cases.\n",
      "93 testing cases.\n"
     ]
    }
   ],
   "source": [
    "print(len(data), 'Total data size.')\n",
    "print(len(train_set), \"training cases.\")\n",
    "print(len(test_set), \"testing cases.\")\n",
    "#prints the number of cases in our total data set, training set, and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pulling appropriate feature and target variables from split datasets.\n",
    "#adapted from assignment 2\n",
    "\n",
    "#The items that have been commented out were originally planned to be used, but our analysis determined that the \n",
    "#variables are closely related to other features\n",
    "#These items remain in case they later need to be used for future analysis\n",
    "y_train = train_set[['W']]    # This pulls the target values from the training set.\n",
    "X1_train = train_set[['GF']]    # This pulls the feature values from the training set.\n",
    "X2_train = train_set[['GA']]\n",
    "#X3_train = train_set[['GoalDif']]\n",
    "X4_train = train_set[['PIM']]\n",
    "#X5_train = train_set[['BenchMinor']]\n",
    "#X6_train = train_set[['PPG']]\n",
    "#X7_train = train_set[['PPC']]\n",
    "X8_train = train_set[['PP%']]\n",
    "X9_train = train_set[['SHA']]\n",
    "#X10_train = train_set[['PKG']]\n",
    "#X11_train = train_set[['PKC']]\n",
    "X12_train = train_set[['PK%']]\n",
    "X13_train = train_set[['SHF']]    \n",
    "\n",
    "y_test = test_set[['W']]    # This pulls the target values from the testing set.\n",
    "X1_test = test_set[['GF']]    # This pulls the feature values from the testing set.\n",
    "X2_test = test_set[['GA']]\n",
    "#X3_test = test_set[['GoalDif']]\n",
    "X4_test = test_set[['PIM']]\n",
    "#X5_test = test_set[['BenchMinor']]\n",
    "#X6_test = test_set[['PPG']]\n",
    "#X7_test = test_set[['PPC']]\n",
    "X8_test = test_set[['PP%']]\n",
    "X9_test = test_set[['SHA']]\n",
    "#X10_test = test_set[['PKG']]\n",
    "#X11_test = test_set[['PKC']]\n",
    "X12_test = test_set[['PK%']]\n",
    "X13_test = test_set[['SHF']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to numpy arrays.\n",
    "#adapted from assignment 2\n",
    "y_train = np.array(y_train)\n",
    "X1_train = np.array(X1_train)\n",
    "X2_train = np.array(X2_train)\n",
    "#X3_train = np.array(X3_train)\n",
    "X4_train = np.array(X4_train)\n",
    "#X5_train = np.array(X5_train)\n",
    "#X6_train = np.array(X6_train)\n",
    "#X7_train = np.array(X7_train)\n",
    "X8_train = np.array(X8_train)\n",
    "X9_train = np.array(X9_train)\n",
    "#X10_train = np.array(X10_train)\n",
    "#X11_train = np.array(X11_train)\n",
    "X12_train = np.array(X12_train)\n",
    "X13_train = np.array(X13_train)\n",
    "\n",
    "y_test = np.array(y_test)\n",
    "X1_test = np.array(X1_test)\n",
    "X2_test = np.array(X2_test)\n",
    "#X3_test = np.array(X3_test)\n",
    "X4_test = np.array(X4_test)\n",
    "#X5_test = np.array(X5_test)\n",
    "#X6_test = np.array(X6_test)\n",
    "#X7_test = np.array(X7_test)\n",
    "X8_test = np.array(X8_test)\n",
    "X9_test = np.array(X9_test)\n",
    "#X10_test = np.array(X10_test)\n",
    "#X11_test = np.array(X11_test)\n",
    "X12_test = np.array(X12_test)\n",
    "X13_test = np.array(X13_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.c_[X1_train,X2_train,X4_train,X8_train,X9_train,X12_train,X13_train]\n",
    "X_test = np.c_[X1_test,X2_test,X4_test,X8_test,X9_test,X12_test,X13_test]\n",
    "#concatenates the relevant feature variables to the training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "We originally planned to use all of the features that were encoded, but after careful analysis, we determined that the features we commented out are closely related to the other features in the model (see heatmap). We have decided to use the following features: Goals-For, Goals-Against, Short-Handed Goals-For, Short-Handed Goals-Against, Penalties-in-Minutes, PowerPlay Percentage, and Penalty-Kill Percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_scale_Train = preprocessing.scale(X_train)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train) \n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Adapted from http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler\n",
    "#and also adapted from the Applying Learning Algorithms Class Demo\n",
    "#Scales the data so that the features do not bias the results (meaning that a feature that ranges from 800 to 1000 \n",
    "#will not have more sway than a feature that runs from 10 to 20, ceteris paribus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Our Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have decided to evaluate the following models: Linear Regression, 2-Degree Polynomial, 7-Degree Polynomial, Lasso Regression, and Ridge Regression. We will compare their cost functions on the training data and select the best model for future calculations. The best model will perform well on the training and testing data, but we will choose one that does not appear to overfit the noise in the data. \n",
    "\n",
    "We are using these models because they all output numerical values that can be used for predictions. Other models, such as classification models, would have been inappropriate for the task of predicting the amount of wins in a season. A classification model would be better suited for predicting whether or not a team is likely to make the playoffs (this is a binary example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create linearRegression object and fit it to your training data\n",
    "#taken from Scikit-Learning and Nonlinear Models demo\n",
    "lr = LinearRegression() #taken from Scikit-Learning and Nonlinear Models demo\n",
    "lr.fit(X_train,y_train) #ties the X_train data with the y_train data to provide a correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.1027027]),\n",
       " array([[ 5.34749648, -4.28585484, -1.35930265,  0.54622815,  0.02096787,\n",
       "          0.23788088, -0.2708182 ]]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displays the thetas\n",
    "lr.intercept_, lr.coef_ #displays the bias and slope of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "Looking at the interpretation of the fifth (short-handed goals allowed) and seventh (short-handed goals for) categories, the model does not make intuitive sense. We would think that by allowing more short-handed goals against, the team would likely win fewer games. In contrast, we would think that by increasing the amount of short-handed goals we score would make us more likely to win more games. This may indicate that linear regression is not the optimal model to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = (lr.coef_.dot(X_train.T)) +lr.intercept_ #creates a variable that makes a prediction based on the \n",
    "                                                     #feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.822907764556371\n"
     ]
    }
   ],
   "source": [
    "linreg_train = mean_squared_error(y_train.T,y_pred_lr)\n",
    "print(linreg_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = (lr.coef_.dot(X_test.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.876327883326493\n"
     ]
    }
   ],
   "source": [
    "linreg_test = mean_squared_error(y_test.T,y_pred_lr)\n",
    "print(linreg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second-Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf=PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly =pf.fit_transform(X_train) #fits to the data and then transforms it\n",
    "lr.fit(X_poly, y_train) #fits the X polynomial data with the target training values\n",
    "#polynomial features already imported, allows us to shape our best fit line to a polynomial with two degrees\n",
    "#taken from the Scikit-Learning and Nonlinear Models demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.34928983]),\n",
       " array([[ 5.32413379e+00, -4.25088516e+00, -1.47982706e+00,\n",
       "          5.30948604e-01,  7.33980578e-02,  1.27149544e-01,\n",
       "         -7.62731553e-02,  3.66901470e-02,  5.50248291e-01,\n",
       "         -1.81558758e-01, -6.23638562e-01, -7.38747146e-02,\n",
       "         -3.60314554e-01, -2.07604352e-01, -2.74404674e-01,\n",
       "          4.02528232e-01, -3.90945490e-01,  2.93295573e-01,\n",
       "          1.62047808e-01, -1.67238990e-01,  1.09265331e-01,\n",
       "         -1.66110522e-01, -4.48909689e-01, -3.85474330e-01,\n",
       "         -1.80476040e-01,  2.93149328e-01,  2.89318628e-01,\n",
       "         -7.05292437e-04,  1.29222657e-01, -3.46382268e-03,\n",
       "         -8.61495340e-02,  1.72519788e-01, -2.22461080e-02,\n",
       "          3.45021573e-01, -3.30889373e-02]]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displays the thetas\n",
    "lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poly_pred = (lr.coef_.dot(X_poly.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.086560257976933\n"
     ]
    }
   ],
   "source": [
    "poly2_train = mean_squared_error(y_train,y_poly_pred.T)\n",
    "print(poly2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_test =pf.fit_transform(X_test)\n",
    "y_poly_pred_test = (lr.coef_.dot(X_poly_test.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.09986664661926\n"
     ]
    }
   ],
   "source": [
    "poly2_test = mean_squared_error(y_test.T,y_poly_pred_test)\n",
    "print(poly2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seventh-Degree Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf=PolynomialFeatures(degree=7, include_bias=False)\n",
    "X_poly7 =pf.fit_transform(X_train) #fits to the data and then transforms it\n",
    "lr.fit(X_poly7, y_train) #fits the X polynomial data with the target training values\n",
    "#polynomial features already imported, allows us to shape our best fit line to a polynomial with two degrees\n",
    "#taken from the Scikit-Learning and Nonlinear Models demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([39.81870316]),\n",
       " array([[ 3.96067028, -2.7600339 ,  0.48309037, ..., -0.07063452,\n",
       "         -0.0340835 , -0.02205356]]))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displays the thetas\n",
    "lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poly7_pred = (lr.coef_.dot(X_poly7.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.388000404863577e-23\n"
     ]
    }
   ],
   "source": [
    "poly7_train = mean_squared_error(y_train,y_poly7_pred.T)\n",
    "print(poly7_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly7_test =pf.fit_transform(X_test)\n",
    "y_poly7_pred_test = (lr.coef_.dot(X_poly7_test.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843361.6970056791\n"
     ]
    }
   ],
   "source": [
    "poly7_test = mean_squared_error(y_test.T,y_poly7_pred_test) #A severe case of overfitting the data\n",
    "print(poly7_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.1027027]),\n",
       " array([ 5.19753212, -4.04095664, -1.35353208,  0.57863987, -0.        ,\n",
       "         0.        , -0.1539975 ]))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This was taken from pg. 132 in the textbook\n",
    "#Completely elimates the weights of the least important features\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso_reg = Lasso(alpha = 0.1)\n",
    "lasso_reg.fit(X_train, y_train)\n",
    "lasso_reg.intercept_, lasso_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "Again we see that an increase in a team's short-handed goals-for is actually decreasing the amount of projected wins for a team in this model. We would not recommend that a team intentionaly try to not score while shorthanded if the opportunity presents itself. It would be difficult to convince us to belive that scoring less while shorthanded would actually increase our odds of winning. \n",
    "\n",
    "It seems that this model found that the short-handed goals against and penalty-kill percentage categories are closely related to the other feature variables and have regressed the impact of those variables to zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lasso_pred = lasso_reg.coef_.dot(X_train.T) +lasso_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.89012251797208\n"
     ]
    }
   ],
   "source": [
    "lasso_train = mean_squared_error(y_train,y_lasso_pred)\n",
    "print(lasso_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lasso_pred_test = lasso_reg.coef_.dot(X_test.T) +lasso_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.925253575852283\n"
     ]
    }
   ],
   "source": [
    "lasso_test = mean_squared_error(y_test,y_lasso_pred_test)\n",
    "print(lasso_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cholesky Solver Closed Form Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.1027027]),\n",
       " array([[ 5.31998838, -4.26110431, -1.35892456,  0.56518224,  0.01415338,\n",
       "          0.22066426, -0.26282032]]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This was taken from pg. 129 in the textbook\n",
    "#Keeps the model weights as small as possible and keeps all the feature variables\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\")\n",
    "ridge_reg.fit(X_train,y_train)\n",
    "ridge_reg.intercept_, ridge_reg.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "Yet again we see that allowing short-handed goals has a positive impact on our model and that increasing the amount of goals we score short-handed has a negative impact on our model. We should consider removing these features from the models to see if our models improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ridge_pred = ridge_reg.coef_.dot(X_train.T) +ridge_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.823576970549146\n"
     ]
    }
   ],
   "source": [
    "ridge_train = mean_squared_error(y_train.T,y_ridge_pred)\n",
    "print(ridge_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ridge_pred_test = ridge_reg.coef_.dot(X_test.T) +ridge_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.871033944340013\n"
     ]
    }
   ],
   "source": [
    "ridge_test = mean_squared_error(y_test.T,y_ridge_pred_test)\n",
    "print(ridge_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Set Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of linear regression on the training set is:  10.822907764556371\n",
      "The cost of a 2-degree polynomial on the training set is:  10.086560257976933\n",
      "The cost of 7-degree polynomial on the training set is:  4.388000404863577e-23\n",
      "The cost of lasso regression on the training set is:  10.89012251797208\n",
      "The cost of ridge regression on the training set is:  10.823576970549146\n"
     ]
    }
   ],
   "source": [
    "print('The cost of linear regression on the training set is: ',linreg_train)\n",
    "print('The cost of a 2-degree polynomial on the training set is: ',poly2_train)\n",
    "print('The cost of 7-degree polynomial on the training set is: ',poly7_train)\n",
    "print('The cost of lasso regression on the training set is: ',lasso_train)\n",
    "print('The cost of ridge regression on the training set is: ',ridge_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "It is clear from the results that the seventh-degree polynomial outperformed all other models on the training set, however, it is very possible that this result is due to the model overfitting the data. We will be able to better see if this is the case when we run the model on the test set.\n",
    "\n",
    "All other models have a similar cost with the second-degree polynomial seeming to have the best result. The second-degree polynomial model is performing at a cost of 10.087 while the linear, lasso, and ridge models are performing at 10.823, 10.890, and 10.824 respectively. From this, the frontrunner for our choice of a model is currently the second-degree polynomial. We will see if this pattern holds when we evaluate the models on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of linear regression on the test set is:  9.876327883326493\n",
      "The cost of a 2-degree polynomial on the test set is:  10.09986664661926\n",
      "The cost of 7-degree polynomial on the test set is:  1843361.6970056791\n",
      "The cost of lasso regression on the test set is:  9.925253575852283\n",
      "The cost of ridge regression on the test set is:  9.871033944340013\n"
     ]
    }
   ],
   "source": [
    "print('The cost of linear regression on the test set is: ',linreg_test)\n",
    "print('The cost of a 2-degree polynomial on the test set is: ',poly2_test)\n",
    "print('The cost of 7-degree polynomial on the test set is: ',poly7_test)\n",
    "print('The cost of lasso regression on the test set is: ',lasso_test)\n",
    "print('The cost of ridge regression on the test set is: ',ridge_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Although the seventh-degree polynomial has the lowest cost on the training set, it exhibits the highest cost on the test set. This is a sign that the model is likely overfitting the data. Thus, we will not use this model going forward.\n",
    "\n",
    "These results show us that although the second-degree polynomial performs the best on our training set, other models perform better on the test set. However, this performance is unusual. Models usually perform slightly worse on the testing set because we expect the model to overfit the data at least a little bit. Because of this reason, and because the models are all approximately within two-tenths of each other, we will likely choose to use the second-degree polynomial for our future models.\n",
    "\n",
    "But first, we want to see if removing the short-handed feature variables will make a difference in our regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Short-handed Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = np.c_[X1_train,X2_train,X4_train,X8_train,X12_train]\n",
    "X_test2 = np.c_[X1_test,X2_test,X4_test,X8_test,X12_test]\n",
    "#X_scale_Train2 = preprocessing.scale(X_train2)\n",
    "#X_scale_Test2 = preprocessing.scale(X_test2)\n",
    "#X_train2 = X_scale_Train2\n",
    "#X_test2 = X_scale_Test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler2 = preprocessing.StandardScaler().fit(X_train2) \n",
    "X_train2 = scaler2.transform(X_train2)\n",
    "X_test2 = scaler2.transform(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.1027027]),\n",
       " array([[ 5.20231265, -4.30453277, -1.42224624,  0.6172244 ,  0.26256171]]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create linearRegression object and fit it to your training data\n",
    "#taken from Scikit-Learning and Nonlinear Models demo\n",
    "lr = LinearRegression() #taken from Scikit-Learning and Nonlinear Models demo\n",
    "lr.fit(X_train2,y_train) #ties the X_train data with the y_train data to provide a correlation\n",
    "lr.intercept_, lr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "After removing the short-handed goals-for and the short-handed goals-against categories, all of our feature variables trend in the direction we would expect. We will run the model to see how it performs relative to the linear regression model that included these two features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = (lr.coef_.dot(X_train2.T)) +lr.intercept_ #creates a variable that makes a prediction based on the \n",
    "                                                     #feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.875139246850242\n"
     ]
    }
   ],
   "source": [
    "linreg_train2 = mean_squared_error(y_train.T,y_pred_lr)\n",
    "print(linreg_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the original linear regression model on the training set is:  10.822907764556371\n",
      "The cost of the new linear regression on the training set is:  10.875139246850242\n"
     ]
    }
   ],
   "source": [
    "print('The cost of the original linear regression model on the training set is: ',linreg_train)\n",
    "print('The cost of the new linear regression on the training set is: ',linreg_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "It appears that by removing the two variables from our model, there is a slightly greater cost on our training set. We will see if this also holds for our testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = (lr.coef_.dot(X_test2.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.874845664199519\n"
     ]
    }
   ],
   "source": [
    "linreg_test2 = mean_squared_error(y_test.T,y_pred_lr)\n",
    "print(linreg_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the original linear regression model on the test set is:  9.876327883326493\n",
      "The cost of the new linear regression on the test set is:  9.874845664199519\n"
     ]
    }
   ],
   "source": [
    "print('The cost of the original linear regression model on the test set is: ',linreg_test)\n",
    "print('The cost of the new linear regression on the test set is: ',linreg_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "Our new model performs slightly better than our original model on the test set. It seems like removing the two features was a good idea, at least for this model. We will see if this is true for the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.1027027]),\n",
       " array([ 5.11288911, -4.04541494, -1.39506347,  0.62147946,  0.        ]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_reg = Lasso(alpha = 0.1)\n",
    "lasso_reg.fit(X_train2, y_train)\n",
    "lasso_reg.intercept_, lasso_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "This model regresses the penalty-kill percentage category down to zero so that the category does not have an impact on the model. This is consistent with the features that the original Lasso Regression model regressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lasso_pred_train2 = lasso_reg.coef_.dot(X_train2.T) +lasso_reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.93682752340272\n"
     ]
    }
   ],
   "source": [
    "lasso_train2 = mean_squared_error(y_train,y_lasso_pred_train2)\n",
    "print(lasso_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the original lasso regression model on the training set is:  10.89012251797208\n",
      "The cost of the new lasso regression on the training set is:  10.93682752340272\n"
     ]
    }
   ],
   "source": [
    "print('The cost of the original lasso regression model on the training set is: ',lasso_train)\n",
    "print('The cost of the new lasso regression on the training set is: ',lasso_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "Like the linear regression model, the original model including the short-handed feature variables is performing better on the training set than the new model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.958145161796107\n"
     ]
    }
   ],
   "source": [
    "y_lasso_pred_test2 = lasso_reg.coef_.dot(X_test2.T) +lasso_reg.intercept_\n",
    "lasso_test2 = mean_squared_error(y_test,y_lasso_pred_test2)\n",
    "print(lasso_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the original lasso regression model on the test set is:  9.925253575852283\n",
      "The cost of the new lasso regression on the test set is:  9.958145161796107\n"
     ]
    }
   ],
   "source": [
    "print('The cost of the original lasso regression model on the test set is: ',lasso_test)\n",
    "print('The cost of the new lasso regression on the test set is: ',lasso_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "The new lasso model does not perform as well as the original model on the test set. However, this difference is very small. We will apply the same steps on the ridge regression model for completion, but we assume that it will produce similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([38.1027027]),\n",
       " array([[ 5.17934774, -4.28228148, -1.42121693,  0.63351071,  0.24621066]]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_reg = Ridge(alpha=1, solver=\"cholesky\")\n",
    "ridge_reg.fit(X_train2,y_train)\n",
    "ridge_reg.intercept_, ridge_reg.coef_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "As predicted, the feature variables are oriented in the expected direction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.875705194587438\n"
     ]
    }
   ],
   "source": [
    "y_ridge_pred2 = ridge_reg.coef_.dot(X_train2.T) +ridge_reg.intercept_\n",
    "ridge_train2 = mean_squared_error(y_train.T,y_ridge_pred2)\n",
    "print(ridge_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the original ridge regression model on the training set is:  10.823576970549146\n",
      "The cost of the new ridge regression on the training set is:  10.875705194587438\n"
     ]
    }
   ],
   "source": [
    "print('The cost of the original ridge regression model on the training set is: ',ridge_train)\n",
    "print('The cost of the new ridge regression on the training set is: ',ridge_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "Once again, the new model performs slightly worse on the training data, but the difference is very small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.876058000020546\n"
     ]
    }
   ],
   "source": [
    "y_ridge_pred_test2 = ridge_reg.coef_.dot(X_test2.T) +ridge_reg.intercept_\n",
    "ridge_test2 = mean_squared_error(y_test.T,y_ridge_pred_test2)\n",
    "print(ridge_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the original ridge regression model on the test set is:  9.871033944340013\n",
      "The cost of the new ridge regression on the test set is:  9.876058000020546\n"
     ]
    }
   ],
   "source": [
    "print('The cost of the original ridge regression model on the test set is: ',ridge_test)\n",
    "print('The cost of the new ridge regression on the test set is: ',ridge_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "The new model performs only slightly worse on the test set than the original model. Although the model does not perform as well, we still consider it an improvement over the original model since we know it makes intuitive sense. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "We will be comparing the new linear, lasso, and ridge regression models with the original 2-degree polynomial model. We have already determined that the 7-degree polynomial is overfitting the data and should not be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Training Set Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the new linear regression model on the training set is:  10.875139246850242\n",
      "The cost of the new lasso regression model on the training set is:  10.93682752340272\n",
      "The cost of the new ridge regression model on the training set is:  10.875705194587438\n",
      "The cost of the 2-degree polynomial model on the training set is:  10.086560257976933\n"
     ]
    }
   ],
   "source": [
    "print('The cost of the new linear regression model on the training set is: ',linreg_train2)\n",
    "print('The cost of the new lasso regression model on the training set is: ',lasso_train2)\n",
    "print('The cost of the new ridge regression model on the training set is: ',ridge_train2)\n",
    "print('The cost of the 2-degree polynomial model on the training set is: ',poly2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Test Set Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost of the new linear regression model on the test set is:  9.874845664199519\n",
      "The cost of the new lasso regression model on the test set is:  9.958145161796107\n",
      "The cost of the new ridge regression model on the test set is:  9.876058000020546\n",
      "The cost of the 2-degree polynomial model on the test set is:  10.09986664661926\n"
     ]
    }
   ],
   "source": [
    "print('The cost of the new linear regression model on the test set is: ',linreg_test2)\n",
    "print('The cost of the new lasso regression model on the test set is: ',lasso_test2)\n",
    "print('The cost of the new ridge regression model on the test set is: ',ridge_test2)\n",
    "print('The cost of the 2-degree polynomial model on the test set is: ',poly2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "After modifying our linear, lasso, and ridge regression models, the second-degree polynomial continues to perform best on the our training data by a margin of eight- to nine-tenths. \n",
    "\n",
    "We normally assume that models will perform worse on the testing set since models tend to overfit noise in the training data. \n",
    "Of all the models, only the second-degree polynomial performs in this expected manner. \n",
    "Because of this, we would expect all of the models to perform worse on the testing data. Since the results of the linear, lasso,and ridge regression models do not perform as expected, we are hesitant to choose any of the models besides the second-degree polynomial. Even so, there is not too much of a performance distance between the models (the difference between linear regression and second-degree polynomial is about 0.225). \n",
    "\n",
    "For these reasons, we will use the second-degree polynomial model as our model of choice for the final steps of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Predictions\n",
    "\n",
    "In the following section, we will use data for several Tampa Bay Lightning seasons that were not included in our original data set. We will run the data through the second-degree polynomial model to further see how well the model performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tampa Bay Lighning 2011 - 2012 Season Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB12_Wins = 46\n",
    "TB12_GF = 232\n",
    "TB12_GA = 209\n",
    "TB12_PIMS = 844\n",
    "TB12_PPP = 18.5\n",
    "TB12_SHA = 8\n",
    "TB12_PKP = 80.7\n",
    "TB12_SHF = 10\n",
    "\n",
    "\n",
    "#taken from:\n",
    "#http://www.nhl.com/stats/team?reportType=season&seasonFrom=20172018&seasonTo=20172018&gameType=2&filter=gamesPlayed,gte,1&sort=points,wins\n",
    "#http://www.espn.com/nhl/statistics/team/_/stat/major-penalties/sort/PIM/year/2018/seasontype/2\n",
    "#http://www.espn.com/nhl/statistics/team/_/stat/special-teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_2012 = np.c_[TB12_GF,TB12_GA,TB12_PIMS,TB12_PPP,TB12_SHA,TB12_PKP,TB12_SHF] \n",
    "#concatenating the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_2012_scaled = scaler.transform(TB_2012)\n",
    "TB_2012 = TB_2012_scaled\n",
    "scaler.transform(TB_2012)\n",
    "TB_2012 = TB_2012.reshape(1,-1)\n",
    "#This code is scaling the new data to match the scale of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf=PolynomialFeatures(degree=2, include_bias=False)\n",
    "TB_2012_poly =pf.fit_transform(TB_2012) #fits to the data and then transforms it\n",
    "lr.fit(X_poly, y_train) #fits the X polynomial data with the target training values\n",
    "#polynomial features already imported, allows us to shape our best fit line to a polynomial with two degrees\n",
    "#taken from the Scikit-Learning and Nonlinear Models demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poly_TB2012 = (lr.coef_.dot(TB_2012_poly.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Model estimates that the Tampa Bay Lightning won 49 games in the 2011-2012 season\n",
      "Tampa Bay actually won 46 games in the 2011-2012 season\n"
     ]
    }
   ],
   "source": [
    "print('Our Model estimates that the Tampa Bay Lightning won', int(y_poly_TB2012), 'games in the 2011-2012 season')\n",
    "print('Tampa Bay actually won', TB12_Wins, 'games in the 2011-2012 season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tampa Bay Lightning 2016 - 2017 Season Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB17_Wins = 42\n",
    "TB17_GF = 230\n",
    "TB17_GA = 224\n",
    "TB17_PIMS = 875\n",
    "TB17_PPP = 22.8\n",
    "TB17_SHA = 8\n",
    "TB17_PKP = 81.4\n",
    "TB17_SHF = 4\n",
    "\n",
    "\n",
    "#taken from:\n",
    "#http://www.nhl.com/stats/team?reportType=season&seasonFrom=20172018&seasonTo=20172018&gameType=2&filter=gamesPlayed,gte,1&sort=points,wins\n",
    "#http://www.espn.com/nhl/statistics/team/_/stat/major-penalties/sort/PIM/year/2018/seasontype/2\n",
    "#http://www.espn.com/nhl/statistics/team/_/stat/special-teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_2017 = np.c_[TB17_GF,TB17_GA,TB17_PIMS,TB17_PPP,TB17_SHA,TB17_PKP,TB17_SHF] \n",
    "#concatenating the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_2017_scaled = scaler.transform(TB_2017)\n",
    "TB_2017 = TB_2017_scaled\n",
    "scaler.transform(TB_2017)\n",
    "TB_2017 = TB_2017.reshape(1,-1)\n",
    "#This code is scaling the new data to match the scale of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf=PolynomialFeatures(degree=2, include_bias=False)\n",
    "TB_2017_poly =pf.fit_transform(TB_2017) #fits to the data and then transforms it\n",
    "lr.fit(X_poly, y_train) #fits the X polynomial data with the target training values\n",
    "#polynomial features already imported, allows us to shape our best fit line to a polynomial with two degrees\n",
    "#taken from the Scikit-Learning and Nonlinear Models demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poly_TB2017 = (lr.coef_.dot(TB_2017_poly.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Model estimates that the Tampa Bay Lightning won 37 games in the 2016-2017 season\n",
      "Tampa Bay actually won 42 games in the 2016-2017 season\n"
     ]
    }
   ],
   "source": [
    "print('Our Model estimates that the Tampa Bay Lightning won', int(y_poly_TB2017), 'games in the 2016-2017 season')\n",
    "print('Tampa Bay actually won', TB17_Wins, 'games in the 2016-2017 season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tampa Bay Lighning 2017 - 2018 Season Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB18_Wins = 54\n",
    "TB18_GF = 296\n",
    "TB18_GA = 236\n",
    "TB18_PIMS = 753\n",
    "TB18_PPP = 23.9\n",
    "TB18_SHA = 3\n",
    "TB18_PKP = 76.1\n",
    "TB18_SHF = 9\n",
    "\n",
    "#taken from:\n",
    "#http://www.nhl.com/stats/team?reportType=season&seasonFrom=20172018&seasonTo=20172018&gameType=2&filter=gamesPlayed,gte,1&sort=points,wins\n",
    "#http://www.espn.com/nhl/statistics/team/_/stat/major-penalties/sort/PIM/year/2018/seasontype/2\n",
    "#http://www.espn.com/nhl/statistics/team/_/stat/special-teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_2018 = np.c_[TB18_GF,TB18_GA,TB18_PIMS,TB18_PPP,TB18_SHA,TB18_PKP,TB18_SHF] \n",
    "#concatenating the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_2018_scaled = scaler.transform(TB_2018)\n",
    "TB_2018 = TB_2018_scaled\n",
    "scaler.transform(TB_2018)\n",
    "TB_2018 = TB_2018.reshape(1,-1)\n",
    "#This code is scaling the new data to match the scale of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf=PolynomialFeatures(degree=2, include_bias=False)\n",
    "TB_2018_poly =pf.fit_transform(TB_2018) #fits to the data and then transforms it\n",
    "lr.fit(X_poly, y_train) #fits the X polynomial data with the target training values\n",
    "#polynomial features already imported, allows us to shape our best fit line to a polynomial with two degrees\n",
    "#taken from the Scikit-Learning and Nonlinear Models demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poly_TB2018 = (lr.coef_.dot(TB_2018_poly.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our Model estimates that the Tampa Bay Lightning won 46 games in the 2017-2018 season\n",
      "Tampa Bay actually won 54 games in the 2017-2018 season\n"
     ]
    }
   ],
   "source": [
    "print('Our Model estimates that the Tampa Bay Lightning won', int(y_poly_TB2018), 'games in the 2017-2018 season')\n",
    "print('Tampa Bay actually won', TB18_Wins, 'games in the 2017-2018 season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tampa Bay Lighning 2018 - 2019 Season Prediction\n",
    "\n",
    "This season has not yet happened. We will attempt to predict the amount of wins the Tampa Bay Lightning will have next season based off of summed averages of the players' career goals for, penalties-in-minutes, and short-handed goals-for. We will use the 2017-2018 season's statistics as inputs for the other feature variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB19_GF = 13/4 + 179/12 + 5/1 + 28/6 + 31/3 + 110/6 + 87/6 + 147/5 + 82/6 + 85/6 + 50/2 + 348/10 + 44/13 + 3/2 + 52/12 + 82/9 + 53/8 + 9/1 + 45/11\n",
    "TB19_GA = 236\n",
    "TB19_PIMS = 214/4 + 414/12 + 6/1 + 112/6 + 60/3 + 126/6 + 268/6 + 161/5 + 156/6 + 109/6 +  38/2 +  440/10 + 656/13 + 73/2 +  302/12 + 485/9 + 221/8 + 38/1 + 243/11\n",
    "TB19_PPP = 23.9\n",
    "TB19_SHA = 3\n",
    "TB19_PKP = 76.1\n",
    "TB19_SHF = 9\n",
    "\n",
    "# Statistics estimated from https://www.nhl.com/lightning/roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_2019 = np.c_[TB19_GF,TB19_GA,TB19_PIMS,TB19_PPP,TB19_SHA,TB19_PKP,TB19_SHF] \n",
    "#concatenating the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_2019_scaled = scaler.transform(TB_2019)\n",
    "TB_2019 = TB_2019_scaled\n",
    "scaler.transform(TB_2019)\n",
    "TB_2019 = TB_2019.reshape(1,-1)\n",
    "#This code is scaling the new data to match the scale of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf=PolynomialFeatures(degree=2, include_bias=False)\n",
    "TB_2019_poly =pf.fit_transform(TB_2019) #fits to the data and then transforms it\n",
    "lr.fit(X_poly, y_train) #fits the X polynomial data with the target training values\n",
    "#polynomial features already imported, allows us to shape our best fit line to a polynomial with two degrees\n",
    "#taken from the Scikit-Learning and Nonlinear Models demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_poly_TB2019 = (lr.coef_.dot(TB_2019_poly.T)) +lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on our model, we expect the Tampa Bay Lightning to win 60 games next season\n"
     ]
    }
   ],
   "source": [
    "print('Based on our model, we expect the Tampa Bay Lightning to win', int(y_poly_TB2019), 'games next season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wins_predict():\n",
    "    '''Predicts the amount of wins a team will win in a season'''\n",
    "    \n",
    "    #The following code will take 8 user inputs\n",
    "    TeamName = input('Enter the name of your team: ')\n",
    "    flag = 0\n",
    "    while flag == 0:\n",
    "        try:\n",
    "            GF = float(input('Enter the amount of goals you predict your team will score: '))\n",
    "            GA = float(input('Enter the amount of goals you predict your team will have scored on them: '))\n",
    "            SHF = float(input('Enter the amount of shorthanded goals you think your team will score next season: '))\n",
    "            SHA = float(input('Enter the amount of shorthanded goals you think your team will allow next season: '))\n",
    "            PIMS = float(input('Enter the amount of penalties-in-minutes you predict your team will accumulate: '))\n",
    "            PPP = float(input('Enter an estimate for your PowerPlay Percentage next season (ex: 21.3): '))\n",
    "            PKP = float(input('Enter an estimate for your Penalty-Kill Percentage next season (ex: 82.6): '))\n",
    "            flag = 1\n",
    "        except ValueError:\n",
    "            print('You did not enter a proper value. Please run the function again.')\n",
    "            return\n",
    "        #This was written ourselves. It allows you to enter in values to see how well your team will perform\n",
    "\n",
    "    \n",
    "    \n",
    "    Season = np.c_[GF,GA,PIMS,PPP,SHA,PKP,SHF] #concatenating the categories\n",
    "    Season_scaled = scaler.transform(Season)\n",
    "    Season = Season_scaled\n",
    "    scaler.transform(Season)\n",
    "    Season = Season.reshape(1,-1) #This code is scaling the new data to match the scale of the training data\n",
    "    \n",
    "    pf=PolynomialFeatures(degree=2, include_bias=False)\n",
    "    Season_poly =pf.fit_transform(Season) #fits to the data and then transforms it\n",
    "    lr.fit(X_poly, y_train) #fits the X polynomial data with the target training values\n",
    "    #polynomial features already imported, allows us to shape our best fit line to a polynomial with two degrees\n",
    "    #taken from the Scikit-Learning and Nonlinear Models demo\n",
    "    \n",
    "    y_poly_Season = (lr.coef_.dot(Season_poly.T)) +lr.intercept_\n",
    "    \n",
    "    #Displays the user inputs as a reminder of the inputted data\n",
    "    #and to provide an easy way to conduct a sensitivity analysis\n",
    "    print('')\n",
    "    print('Your inputted values:')\n",
    "    print('Team Name:', TeamName)\n",
    "    print('Goals For:', GF)\n",
    "    print('Goals Against: ', GA)\n",
    "    print('Short-Handed Goals-For: ',SHF)\n",
    "    print('Short-Handed Goals-Against: ',SHA)\n",
    "    print('Penalties-in-Minutes: ', PIMS)\n",
    "    print('PowerPlay Percentage: ',PPP)\n",
    "    print('Penalty-Kill Percentage: ',PKP)\n",
    "    print('')\n",
    "    print('Based on our model, we expect your team to win', int(y_poly_Season), 'games next season')\n",
    "    if 82 >= y_poly_Season > 65:\n",
    "        print('')\n",
    "        print('You are expected to win a large amount of games. You may want to reevaluate your inputs.')\n",
    "    elif y_poly_Season > 82:\n",
    "        print('')\n",
    "        print('You are expected to win more games than possible. We strongly recommend reevaluating your inputs to make sure that they seem realistic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the name of your team: TBL\n",
      "Enter the amount of goals you predict your team will score: 220\n",
      "Enter the amount of goals you predict your team will have scored on them: 350\n",
      "Enter the amount of shorthanded goals you think your team will score next season: 4\n",
      "Enter the amount of shorthanded goals you think your team will allow next season: 6\n",
      "Enter the amount of penalties-in-minutes you predict your team will accumulate: 1200\n",
      "Enter an estimate for your PowerPlay Percentage next season (ex: 21.3): 20\n",
      "Enter an estimate for your Penalty-Kill Percentage next season (ex: 82.6): 81.5\n",
      "\n",
      "Your inputted values:\n",
      "Team Name: TBL\n",
      "Goals For: 220.0\n",
      "Goals Against:  350.0\n",
      "Short-Handed Goals-For:  4.0\n",
      "Short-Handed Goals-Against:  6.0\n",
      "Penalties-in-Minutes:  1200.0\n",
      "PowerPlay Percentage:  20.0\n",
      "Penalty-Kill Percentage:  81.5\n",
      "\n",
      "Based on our model, we expect your team to win 15 games next season\n"
     ]
    }
   ],
   "source": [
    "wins_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We conclude that by using the second-degree polynomial model, General Managers of the National Hockey League will be able to have an accurate prediction of how many games their team is likely to win. Since the cost function on the testing set of this model is roughly 10.1, it means that the model is accurate to within +/- 3.26 games on average (root mean squared error). While we see that it does hold true for the 2012 model (the projection is three goals more than they actually won), we see that it is off by 5 games for the 2017 model, and by 8 games for the 2018 model. One possible reason for this is that the hockey has evolved and thus has made the data set less relevent (our data runs from 1995 to 2011). Another reason could be that the Tampa Bay Lightning is a slight outlier for the model: the Lightning performed exceptionally well during the 2017-2018 regular season. \n",
    "\n",
    "Nevertheless, the model does provide a good estimate for how many games a team will win in a season. In practice, GMs could take a sum of their players' individual statistics to predict the team's goals-for, goals-against, powerplay percentage, penalty kill percentage, penalties-in-minutes, short-handed goals-for, and short-handed goals-against, and then plug those results into the model. This would allow the GM to predict their team's wins for the upcoming season. We did this for the Tampa Bay Lightning and we expect them to win 60 games next season (as Tampa Bay fans, we sincerely hope that this prediction is true).\n",
    "\n",
    "The General Manager could also complete this same process for all teams in their division, conference, or even the entire league to predict the final standings for that season. This would provide GMs a good idea of how likely they are to make the playoffs that year. \n",
    "\n",
    "The General Manager would be able to use this model to evaluate the value of potential trades. They could remove the stats of the players that they are giving up from the projected average used to calculate the results of the upcoming season and then include the projected statistics of the players that they would potentially gain from the trade. The GM could then see how this trade is likely to affect the team's wins in the upcoming season. If the team were to make a trade mid-season, they could simply pro-rate the necessary calculations to predict the amount of wins at the end of the season.\n",
    "\n",
    "A downside to using this model is that it does not specifically account for players who may not have good chemistry with the other players in the organization. If the GM trades for a player that does not fit into the system and does not perform as well as they usually do, the actual amount of wins the team has may end up varying significantly from the projected amount of wins. However, the converse of this is also true: a player may fit very well with the organization and exceed expectations. This same line of thinking also applies to players who may go into a slump next season and players who might have a breakout season. Finally, one last downside is that the model will have trouble predicting if players have not yet played a significant number of seasons in the NHL and values used within the model are inaccurate. However, these are not faults of the model and are instead faults of the input data. It is our belief that using this model would provide a General Manager with much more insight that they would have if they were to simply follow their gut instinct or use other traditional methods, which are subject to the same downsides as our model.  \n",
    "\n",
    "By using our second-degree polynomial model, General Managers will have a good idea of how well the team is likely to perform in upcoming seasons. The GMs could use this information to make smart trades that are likely to improve the team's record. Although the model is not without defects, these defects are not due to the model itself and are instead due to unpredictible events that are difficult to forecast. Additional models may be created in the future that, when combined with our model, help to improve our model's accuracy and provide General Managers with more accurate insight. In all, this model appears to do well at measuring what it purports to measure, and so will help General Managers bring a little more certainty into a game that is riddled with uncertainty.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
